% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read-write.R
\name{spark_write_json}
\alias{spark_write_json}
\title{Write a \code{spark_tbl} to json file}
\usage{
spark_write_json(.data, path, mode = "error", partition_by = NULL, ...)
}
\arguments{
\item{.data}{a \code{spark_tbl}}

\item{path}{string, the path where the file is to be saved.}

\item{mode}{string, usually \code{"error"} (default), \code{"overwrite"},
\code{"append"}, or \code{"ignore"}}

\item{partition_by}{string, column names to partition by on disk}

\item{...}{any other named options. See details below.}
}
\description{
Write a \code{spark_tbl} to a json file.
}
\details{
For text, a few additional options can be specified using \code{...}:
#' \describe{
  \item{compression}{(default null), compression codec to use when saving to
  file. This can be one of the known case-insensitive shorten names (none,
  bzip2, gzip, lz4, snappy and deflate)}
  \item{replaceWhere}{(default null), You can selectively overwrite only
  the data that matches predicates over partition columns (e.g. "date >=
  '2017-01-01' AND date <= '2017-01-31'")}
  \item{overwriteSchema}{(default FALSE), when overwriting a table using
  mode("overwrite") without replaceWhere, you may still want to overwrite
  the schema of the data being written. You replace the schema and
  partitioning of the table by setting this param option to \code{TRUE}}
}
https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameWriter.html#json-java.lang.String-
}
