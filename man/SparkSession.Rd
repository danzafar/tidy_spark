% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SparkSession.R
\docType{data}
\name{SparkSession}
\alias{SparkSession}
\title{The \code{SparkSession} Class}
\format{An object of class \code{R6ClassGenerator} of length 24.}
\usage{
SparkSession
}
\arguments{
\item{session_jobj}{the session's jobj}

\item{start}{integer, starting value}

\item{end}{integer, ending value}

\item{step}{integer, the number of steps}

\item{numPartitions}{integer, the target number of partitions}

\item{sqlText}{string, a SQL query

Table}

\item{tableName}{is either a qualified or unqualified name that designates
a table or view. If a database is specified, it identifies the table/view
from the database. Otherwise, it first attempts to find a temporary view
with the given name and then match the table/view from the current
database. Note that, the global temporary view database is also valid here.}
}
\value{
a \code{spark_tbl}
SQL

a \code{spark_tbl}

Version
}
\description{
This class was designed as a thin wrapper around Spark's
\code{SparkSession}. It is initialized when \code{spark_submit} is called.
Note, running. \code{sc$stop} will end your session. For information on
methods and types requirements, refer to the Javadoc:
https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/sql/SparkSession.html

Create a new \code{SparkSession}

print \code{SparkSession}

Stop the underlying SparkContext.

Returns a DataFrame with no rows or columns.
Range

Creates a Dataset with a single LongType column named id,
containing elements in a range from start to end (exclusive) with a step
value, with partition number specified.

Executes a SQL query using Spark, returning the result as a
DataFrame. The dialect that is used for SQL parsing can be configured
with 'spark.sql.dialect'.

Returns the specified table/view as a DataFrame.

The version of Spark on which this application is running.
}
\details{
Not all methods are implemented due to compatability
and tidyspark best practice usage conflicts. If you need to use a method not
included, try calling it using \code{call_method(sc$jobj, <yourMethod>)}.
}
\section{Fields}{

\describe{
\item{\code{jobj}}{\code{SparkSession} java object}

\item{\code{conf}}{get the \code{RuntimeConfig}}

\item{\code{sparkContext}}{the sparkContext associated with the session}
}}

\examples{
\dontrun{

spark <- spark_session()
rdd <- spark$range(1, 10)
rdd$collect()

spark_session_stop()
}

}
\keyword{datasets}
