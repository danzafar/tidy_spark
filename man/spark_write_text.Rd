% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read-write.R
\name{spark_write_text}
\alias{spark_write_text}
\title{Write a \code{spark_tbl} to text file}
\usage{
spark_write_text(.data, path, mode = "error", partition_by = NULL, ...)
}
\arguments{
\item{.data}{a \code{spark_tbl}}

\item{path}{string, the path where the file is to be saved.}

\item{mode}{string, usually \code{"error"} (default), \code{"overwrite"},
\code{"append"}, or \code{"ignore"}}

\item{partition_by}{string, column names to partition by on disk}

\item{...}{any other named options. See details below.}
}
\description{
Write a \code{spark_tbl} to a text file.
}
\details{
For text, two additional options can be specified using \code{...}:
#' \describe{
  \item{compression}{(default \code{null}), compression codec to use when saving to
  file. This can be one of the known case-insensitive shorten names (none,
  bzip2, gzip, lz4, snappy and deflate).}
  \item{lineSep}{(default \code{\\n}), defines the line separator that should be used for writing.}
}
https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameWriter.html#text-java.lang.String-
}
