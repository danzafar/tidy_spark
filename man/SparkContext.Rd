% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sparkContext.R
\name{SparkContext}
\alias{SparkContext}
\title{The \code{SparkContext} Class}
\description{
This class was designed as a thin wrapper around Spark's
\code{SparkContext}. It is initialized when \code{spark_submit} is called
and inserted into the workspace as \code{sc}. Note, running
\code{sc$stop} will end your session. For information on methods and types
requirements, refer to the \href{https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html}{javadoc}:
}
\details{
Not all methods are implemented due to compatability
and tidyspark best practice usage conflicts. If you need to use a method not
included, try calling it using \code{call_method(sc$jobj, <yourMethod>)}.
}
\examples{
\dontrun{
spark <- spark_session()
sc <- spark$sparkContext
sc$defaultParallelism()
an_rdd <- sc$parallelize(list(1:10), 4)
sc$getConf$get("spark.submit.deployMode")

spark_session_stop()
}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{jobj}}{\code{SparkContext} java object}

\item{\code{getConf}}{get the \code{SparkConf}}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{SparkContext$new()}}
\item \href{#method-print}{\code{SparkContext$print()}}
\item \href{#method-addFile}{\code{SparkContext$addFile()}}
\item \href{#method-addJar}{\code{SparkContext$addJar()}}
\item \href{#method-appName}{\code{SparkContext$appName()}}
\item \href{#method-broadcast}{\code{SparkContext$broadcast()}}
\item \href{#method-cancelAllJobs}{\code{SparkContext$cancelAllJobs()}}
\item \href{#method-cancelJobGroup}{\code{SparkContext$cancelJobGroup()}}
\item \href{#method-clearJobGroup}{\code{SparkContext$clearJobGroup()}}
\item \href{#method-defaultMinPartitions}{\code{SparkContext$defaultMinPartitions()}}
\item \href{#method-defaultParallelism}{\code{SparkContext$defaultParallelism()}}
\item \href{#method-emptyRDD}{\code{SparkContext$emptyRDD()}}
\item \href{#method-isLocal}{\code{SparkContext$isLocal()}}
\item \href{#method-jars}{\code{SparkContext$jars()}}
\item \href{#method-master}{\code{SparkContext$master()}}
\item \href{#method-parallelize}{\code{SparkContext$parallelize()}}
\item \href{#method-setCheckpointDir}{\code{SparkContext$setCheckpointDir()}}
\item \href{#method-setJobDescription}{\code{SparkContext$setJobDescription()}}
\item \href{#method-setJobGroup}{\code{SparkContext$setJobGroup()}}
\item \href{#method-setLocalProperty}{\code{SparkContext$setLocalProperty()}}
\item \href{#method-sparkUser}{\code{SparkContext$sparkUser()}}
\item \href{#method-startTime}{\code{SparkContext$startTime()}}
\item \href{#method-stop}{\code{SparkContext$stop()}}
\item \href{#method-textFile}{\code{SparkContext$textFile()}}
\item \href{#method-version}{\code{SparkContext$version()}}
\item \href{#method-union}{\code{SparkContext$union()}}
\item \href{#method-wholeTextFiles}{\code{SparkContext$wholeTextFiles()}}
\item \href{#method-clone}{\code{SparkContext$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new \code{SparkContext}
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$new(sc = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{sc}}{optional, can instatiate with another SparkContext's jobj.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-print"></a>}}
\if{latex}{\out{\hypertarget{method-print}{}}}
\subsection{Method \code{print()}}{
print \code{SparkContext}
Add File
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$print()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addFile"></a>}}
\if{latex}{\out{\hypertarget{method-addFile}{}}}
\subsection{Method \code{addFile()}}{
Add a file to be downloaded with this Spark job on every node.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$addFile(path, recursive = F)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{path}}{string}

\item{\code{recursive}}{boolean
Add Jar}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addJar"></a>}}
\if{latex}{\out{\hypertarget{method-addJar}{}}}
\subsection{Method \code{addJar()}}{
Adds a JAR dependency for all tasks to be executed on this SparkContext in
the future.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$addJar(path)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{path}}{string
App Name}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-appName"></a>}}
\if{latex}{\out{\hypertarget{method-appName}{}}}
\subsection{Method \code{appName()}}{
get the App name
Broadcast
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$appName()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-broadcast"></a>}}
\if{latex}{\out{\hypertarget{method-broadcast}{}}}
\subsection{Method \code{broadcast()}}{
Broadcast a vairable to executors.
cancelAllJobs
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$broadcast(value)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{value}}{the variable to broadcast.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-cancelAllJobs"></a>}}
\if{latex}{\out{\hypertarget{method-cancelAllJobs}{}}}
\subsection{Method \code{cancelAllJobs()}}{
Cancel all jobs that have been scheduled or are running.
cancelJobGroup
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$cancelAllJobs()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-cancelJobGroup"></a>}}
\if{latex}{\out{\hypertarget{method-cancelJobGroup}{}}}
\subsection{Method \code{cancelJobGroup()}}{
Cancel active jobs for the specified group.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$cancelJobGroup(groupId)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{groupId}}{string
clearJobGroup}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clearJobGroup"></a>}}
\if{latex}{\out{\hypertarget{method-clearJobGroup}{}}}
\subsection{Method \code{clearJobGroup()}}{
Clear the current thread's job group ID and its description.
defaultMinPartitions
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$clearJobGroup()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-defaultMinPartitions"></a>}}
\if{latex}{\out{\hypertarget{method-defaultMinPartitions}{}}}
\subsection{Method \code{defaultMinPartitions()}}{
Default min number of partitions for Hadoop RDDs when not given by user
Notice that we use math.min so the "defaultMinPartitions" cannot be higher
than 2.
defaultParallelism
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$defaultMinPartitions()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-defaultParallelism"></a>}}
\if{latex}{\out{\hypertarget{method-defaultParallelism}{}}}
\subsection{Method \code{defaultParallelism()}}{
Default level of parallelism to use when not given by user
emptyRDD
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$defaultParallelism()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-emptyRDD"></a>}}
\if{latex}{\out{\hypertarget{method-emptyRDD}{}}}
\subsection{Method \code{emptyRDD()}}{
Get an RDD that has no partitions or elements.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$emptyRDD()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
RDD
isLocal
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-isLocal"></a>}}
\if{latex}{\out{\hypertarget{method-isLocal}{}}}
\subsection{Method \code{isLocal()}}{
is the Spark process local?
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$isLocal()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
boolean
jars
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-jars"></a>}}
\if{latex}{\out{\hypertarget{method-jars}{}}}
\subsection{Method \code{jars()}}{
is the Spark process local?
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$jars()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
a jobj representing \code{scala.collection.Seq<String>}
master
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-master"></a>}}
\if{latex}{\out{\hypertarget{method-master}{}}}
\subsection{Method \code{master()}}{
why is roxygen making me do all these...
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$master()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
string
Parallelize
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-parallelize"></a>}}
\if{latex}{\out{\hypertarget{method-parallelize}{}}}
\subsection{Method \code{parallelize()}}{
Distribute a list (or Scala collection) to form an RDD.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$parallelize(seq, numSlices = 1L)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{seq}}{list (or Scala Collection) to distribute}

\item{\code{numSlices}}{number of partitions to divide the collection into}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
Parallelize acts lazily. If seq is a mutable collection and is
altered after the call to parallelize and before the first action on the
RDD, the resultant RDD will reflect the modified collection. Pass a copy
of the argument to avoid this., avoid using parallelize(Seq()) to create
an empty RDD. Consider emptyRDD for an RDD with no partitions, or
parallelize(Seq[T]()) for an RDD of T with empty partitions.
}

\subsection{Returns}{
RDD
setCheckpointDir
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-setCheckpointDir"></a>}}
\if{latex}{\out{\hypertarget{method-setCheckpointDir}{}}}
\subsection{Method \code{setCheckpointDir()}}{
Set the directory under which RDDs are going to be checkpointed.
setJobDescription
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$setCheckpointDir(directory)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{directory}}{string, path to the directory where checkpoint files will
be stored (must be HDFS path if running in cluster)}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-setJobDescription"></a>}}
\if{latex}{\out{\hypertarget{method-setJobDescription}{}}}
\subsection{Method \code{setJobDescription()}}{
Set a human readable description of the current job.
setJobGroup
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$setJobDescription(value)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{value}}{string}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-setJobGroup"></a>}}
\if{latex}{\out{\hypertarget{method-setJobGroup}{}}}
\subsection{Method \code{setJobGroup()}}{
Assigns a group ID to all the jobs started by this thread until the
group ID is set to a different value or cleared.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$setJobGroup(groupId, description, interruptOnCancel)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{groupId}}{string}

\item{\code{description}}{string}

\item{\code{interruptOnCancel}}{If TRUE, then job cancellation will result in
Thread.interrupt() being called on the job's executor threads. This is
useful to help ensure that the tasks are actually stopped in a timely
manner, but is off by default due to HDFS-1208, where HDFS may respond to
Thread.interrupt() by marking nodes as dead.
setLocalProperty}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-setLocalProperty"></a>}}
\if{latex}{\out{\hypertarget{method-setLocalProperty}{}}}
\subsection{Method \code{setLocalProperty()}}{
Set a local property that affects jobs submitted from this thread, such
as the Spark fair scheduler pool.
sparkuser
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$setLocalProperty(key, value)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{key}}{string}

\item{\code{value}}{string}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-sparkUser"></a>}}
\if{latex}{\out{\hypertarget{method-sparkUser}{}}}
\subsection{Method \code{sparkUser()}}{
Who AM I?
startTime
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$sparkUser()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-startTime"></a>}}
\if{latex}{\out{\hypertarget{method-startTime}{}}}
\subsection{Method \code{startTime()}}{
still surprised I have to write these. but the big bad orange
warnings that roxygen throws are just sooooo ugly
stop
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$startTime()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-stop"></a>}}
\if{latex}{\out{\hypertarget{method-stop}{}}}
\subsection{Method \code{stop()}}{
Shut down the SparkContext.
textFile
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$stop()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-textFile"></a>}}
\if{latex}{\out{\hypertarget{method-textFile}{}}}
\subsection{Method \code{textFile()}}{
Read a text file from HDFS, a local file system (available
on all nodes), or any Hadoop-supported file system URI, and return it as
an RDD of Strings.
version
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$textFile(path, minPartitions)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{path}}{string, path to the text file on a supported file system}

\item{\code{minPartitions}}{int, suggested minimum number of partitions for the
resulting RDD}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-version"></a>}}
\if{latex}{\out{\hypertarget{method-version}{}}}
\subsection{Method \code{version()}}{
The version of Spark on which this application is running.
Union RDDs
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$version()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-union"></a>}}
\if{latex}{\out{\hypertarget{method-union}{}}}
\subsection{Method \code{union()}}{
Build the union of a list of RDDs.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$union(rdds)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{rdds}}{a list of RDDs or RDD jobjs}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
RDD
wholeTextFiles
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-wholeTextFiles"></a>}}
\if{latex}{\out{\hypertarget{method-wholeTextFiles}{}}}
\subsection{Method \code{wholeTextFiles()}}{
Read a directory of text files from HDFS, a local file system
(available on all nodes), or any Hadoop-supported file system URI.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$wholeTextFiles(path, minPartitions)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{path}}{Directory to the input data files, the path can be comma
separated paths as the list of inputs.}

\item{\code{minPartitions}}{A suggestion value of the minimal splitting number
for input data.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
RDD
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SparkContext$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
