% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ml_clustering.R
\name{ml_assign_clusters}
\alias{ml_assign_clusters}
\alias{ml_assign_clusters,spark_tbl}
\title{PowerIterationClustering}
\usage{
ml_assign_clusters(
  data,
  k = 2L,
  initMode = c("random", "degree"),
  maxIter = 20L,
  sourceCol = "src",
  destinationCol = "dst",
  weightCol = NULL
)
}
\arguments{
\item{data}{a spark_tbl.}

\item{k}{the number of clusters to create.}

\item{initMode}{the initialization algorithm; "random" or "degree"}

\item{maxIter}{the maximum number of iterations.}

\item{sourceCol}{the name of the input column for source vertex IDs.}

\item{destinationCol}{the name of the input column for destination vertex IDs}

\item{weightCol}{weight column name. If this is not set or \code{NULL},
we treat all instance weights as 1.0.}

\item{...}{additional argument(s) passed to the method.}
}
\value{
A dataset that contains columns of vertex id and the corresponding cluster for the id.
        The schema of it will be: \code{id: integer}, \code{cluster: integer}
}
\description{
A scalable graph clustering algorithm. Users can call \code{ml_assign_clusters} to
return a cluster assignment for each input vertex.
Run the PIC algorithm and returns a cluster assignment for each input vertex.
}
\note{
ml_assign_clusters(spark_tbl) since 3.0.0
}
\examples{
\dontrun{
df <- spark_tbl(
  tribble(~src, ~dst, ~weight,
          0L, 1L, 1.0,
          0L, 2L, 1.0,
          1L, 2L, 1.0,
          3L, 4L, 1.0,
          4L, 0L, 0.1))
clusters <- ml_assign_clusters(df, initMode = "degree", weightCol = "weight")
show(clusters)
}
}
